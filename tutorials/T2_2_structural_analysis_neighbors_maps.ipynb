{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceae7727",
   "metadata": {},
   "source": [
    "Interactive version of the tutorial: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/pgrigorev/ModMatEcole/HEAD?labpath=tutorials%2FT2_2_structural_analysis_neighbors_maps.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e44cd6b-49b3-42d5-821b-021cab598aee",
   "metadata": {},
   "source": [
    "**Setup necessary packages (in binder environment it is already installed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e8c11-13ba-4f96-9dc7-3375ee794ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/arn-all/neighbors-maps ase plotly scikit-learn matplotlib matscipy numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2886ab-06a6-453a-a9e2-676f3ac879d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "import ase.lattice\n",
    "import ase.lattice.tetragonal\n",
    "import ase.lattice.monoclinic\n",
    "import ase.lattice.triclinic\n",
    "import ase.lattice.cubic\n",
    "import ase.lattice.hexagonal\n",
    "import ase.lattice.orthorhombic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# For descriptors\n",
    "from neighbors_map import Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058913f-cb4a-4c2b-8c7b-a726c79b5366",
   "metadata": {},
   "source": [
    "## 1. Create synthetic data\n",
    "\n",
    "We will use ASE to generate a dataset of simple crystal structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711a4ca-6ad9-4428-9667-e12096cb6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 7 Bravais Lattices to consider\n",
    "# Each entry is a tuple: (crystal system, lattice type, lattice constants)\n",
    "bravais_lattices = [\n",
    "    (\"cubic\", \"SimpleCubic\", 3.0),  # Simple cubic lattice (single constant)\n",
    "    (\"cubic\", \"FaceCenteredCubic\", 3.0),  # Face-centered cubic (single constant)\n",
    "    (\"cubic\", \"BodyCenteredCubic\", 3.0),  # Body-centered cubic (single constant)\n",
    "    (\"cubic\", \"Diamond\", 3.0),  # Diamond cubic (single constant)\n",
    "    # For orthorhombic, we need 3 constants: a, b/a (ratio), c/a (ratio)\n",
    "    (\"orthorhombic\", \"BaseCenteredOrthorhombic\", {'a': 3.0, 'b/a': 1.2, 'c/a': 1.5}), \n",
    "    (\"orthorhombic\", \"FaceCenteredOrthorhombic\", {'a': 3.0, 'b/a': 1.2, 'c/a': 1.7}),\n",
    "    (\"orthorhombic\", \"BodyCenteredOrthorhombic\", {'a': 3.0, 'b/a': 1.2, 'c/a': 1.5}),\n",
    "]\n",
    "\n",
    "# Function to Create a Lattice\n",
    "def generate_lattice(lattice_module, lattice_class, element, size, lattice_constants):\n",
    "    \"\"\"\n",
    "    Creates an atomic lattice using the ASE (Atomic Simulation Environment) library.\n",
    "\n",
    "    Args:\n",
    "        lattice_module (str): The crystal system (e.g., \"cubic\", \"orthorhombic\")\n",
    "        lattice_class (str): The specific Bravais lattice type (e.g., \"SimpleCubic\")\n",
    "        element (str): The chemical symbol of the element (e.g., \"Fe\" for iron). This won't change anything for this tutorial.\n",
    "        size (tuple): The size of the lattice in terms of unit cells (e.g., (4, 4, 4))\n",
    "        lattice_constants (float or dict): \n",
    "            - If float: The lattice constant for cubic systems.\n",
    "            - If dict: A dictionary of lattice constants for orthorhombic systems.\n",
    "    \n",
    "    Returns:\n",
    "        Atoms: An Atoms object representing the created lattice.\n",
    "    \"\"\"\n",
    "    lattice_type = getattr(getattr(ase.lattice, lattice_module), lattice_class)\n",
    "    lattice = lattice_type(element, size=size, latticeconstant=lattice_constants)\n",
    "    return Atoms(lattice)\n",
    "\n",
    "\n",
    "# Generate Lattices and Store Them as Lists\n",
    "lattices = []     # List to store the created lattice objects\n",
    "lattice_num = []  # List of class labels in the form of numbers (will be useful for classification) \n",
    "lattice_name = [] # List to store the actual human-readable lattice names \n",
    "\n",
    "for i, (lattice_type, lattice_class, lattice_constants) in enumerate(bravais_lattices):\n",
    "    # 'enumerate' gives us both the index (i) and the tuple from the list\n",
    "    \n",
    "    lattices.append(generate_lattice(lattice_type, lattice_class, \"Fe\", (6, 6, 6), lattice_constants))\n",
    "    lattice_num.append(i)         \n",
    "    lattice_name.append(lattice_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f71f8-6231-461b-9e97-8887e51a5869",
   "metadata": {},
   "source": [
    "Here is what we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef4b2a-2a97-43d6-a61f-deddd7fdedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e3f36-8138-4dbf-b5b1-37a51b073559",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351afbb-99c4-4ce7-acde-92b47801fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c4bff-bef8-40fa-81d9-81c35637c773",
   "metadata": {},
   "source": [
    "## 2. On the choice of a cut-off radius \n",
    "\n",
    "- The cut-off radius is a critical parameter as it controls the locality assumption that is made when we talk about a *local* atomic environment\n",
    "- Some processes or transformations will be much easier to detect with a longer cut-off radius, while increased computational cost and signal averaging are more likely for long cut-offs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bb0d2-30a4-44b1-95b3-34a6e3548c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff(atoms, n_neighbors, cutoff=10.):\n",
    "    \"\"\"\n",
    "    Function to get the distance of n_th neighbour using matscipy neighbor list.\n",
    "    \"\"\"\n",
    "    from matscipy.neighbours import neighbour_list  # Import the neighbor list tool\n",
    "\n",
    "    # Create the neighbor list\n",
    "    # This finds all pairs of atoms within the 'cutoff' distance and stores their\n",
    "    # indices (i) and distances (d) in arrays.\n",
    "    i, d = neighbour_list(\"id\", atoms, cutoff=cutoff)  \n",
    "\n",
    "    # Focus on the first atom (index 0)\n",
    "    # This extracts only the distances from the first atom to its neighbors.\n",
    "    first_atom_d = d[i == 0] \n",
    "\n",
    "    # Sort the distances\n",
    "    first_atom_d.sort()\n",
    "\n",
    "    # Get the n-th neighbor distance\n",
    "    # After sorting, the distance at index (n_neighbors) will be the distance to \n",
    "    # the n-th nearest neighbor of the first atom.\n",
    "    return first_atom_d[n_neighbors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd62e0-a804-4a22-8051-8a2502b0cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neighbors we're interested in\n",
    "n_neighbors = [24, 32, 64, 128]\n",
    "\n",
    "# Create a range of 20 cutoff distances to test (from 1 Angstrom to 150 Angstroms)\n",
    "X = np.linspace(1, 128, 25, dtype=int)  \n",
    "\n",
    "print(lattice_name[1])\n",
    "\n",
    "# Calculate cutoff radii for each desired number of neighbors in this structure\n",
    "cutoff_radii = [get_cutoff(lattices[1], x) for x in X]\n",
    "\n",
    "# Plot the relationship between cutoff radius and number of neighbors (black line)\n",
    "plt.plot(cutoff_radii, X, \".-\", color='k', alpha=0.8)  \n",
    "\n",
    "\n",
    "# Add horizontal dashed lines for the desired number of neighbors\n",
    "for neighbor_count in n_neighbors:\n",
    "    plt.hlines(neighbor_count, xmin=min(cutoff_radii), xmax=max(cutoff_radii), linestyle=\":\", alpha=0.5)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel(r\"Cut-off radius $\\AA$\")  # $\\AA$ is the Angstrom symbol in LaTeX\n",
    "plt.ylabel(\"Number of neighbors\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a021d-b51e-4537-9422-21af8d0460db",
   "metadata": {},
   "source": [
    "NB: In perfect crystals, the number of atoms within a cut-off radius is not a smooth or linear function.\n",
    "Above, we show the number of neighbors found within a certain cut-off radius, for a perfect crystal (black)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344dc47-4248-4deb-8dec-c9642a0e428c",
   "metadata": {},
   "source": [
    "## 3. Effect of the cut-off radius on atomic descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c83c7-7bb3-4c44-b5db-d0a70f73d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nm(ax, number_of_neighbors_in_rcut=32):\n",
    "    \"\"\"\n",
    "    Plots neighbor maps for each lattice, showing the effect of the specified cutoff radius (rows).\n",
    "\n",
    "    Args:\n",
    "        ax: The subplot axes where the neighbor map will be plotted.\n",
    "        number_of_neighbors_in_rcut (int): The desired number of neighbors within \n",
    "            the cutoff radius. Defaults to 32.\n",
    "    \"\"\"\n",
    "\n",
    "    for i, (lattice, bravais) in enumerate(zip(lattices, bravais_lattices)): \n",
    "\n",
    "        # Create an Atoms object from the lattice data\n",
    "        lat = Atoms(lattice)  \n",
    "\n",
    "        # --- Optional: Adjust Neighbor Map Parameters ---\n",
    "        # (Uncomment to experiment with different settings)\n",
    "        # lat.neighbor_map.beta = 3    \n",
    "        # lat.neighbor_map.gamma = 2 \n",
    "\n",
    "        # Get the neighbor map using the specified cutoff radius\n",
    "        cutoff_radius = get_cutoff(lat, number_of_neighbors_in_rcut)\n",
    "        image = lat.get_neighbor_map(0, r_cut=cutoff_radius)  # 0 means focus on the first atom\n",
    "\n",
    "        # Display the neighbor map as an image\n",
    "        ax[i].imshow(image)  \n",
    "        ax[i].axis(\"off\")   # Turn off axis labels for a cleaner look\n",
    "\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axs = plt.subplots(len(n_neighbors), len(lattices), figsize=(6, 5), dpi=300, constrained_layout=True)\n",
    "\n",
    "# Generate neighbor maps for different numbers of neighbors (rows)\n",
    "for i, n in enumerate(n_neighbors): \n",
    "    plot_nm(ax=axs[i], number_of_neighbors_in_rcut=n)\n",
    "\n",
    "# Add titles above each column (lattice type)\n",
    "for i, _ in enumerate(lattices):\n",
    "    for j, n_neigh in enumerate(n_neighbors):\n",
    "        axs[j, i].set_title(f\"{bravais_lattices[i][1]}\\n n={n_neigh}\", fontsize=4)  \n",
    "\n",
    "\n",
    "plt.suptitle(r\"Neighbors maps with an increasingly large number of atoms in $r_{cut}$\", size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a14237-6d66-4de3-ac46-ce359843a7c8",
   "metadata": {},
   "source": [
    "- Visually, do the images above (for a given row) seem different enough to be classified ?\n",
    "- **Images stongly depend on the cut-off radius -> comparison should be done for a given rcut and values of beta and gamma**\n",
    "\n",
    "- These images are for perfect crystalline structures. A descriptor is useful only if it can recognize them in the wild (i.e. in the presence of noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f112ed-0120-49c6-90e5-c7218baac15e",
   "metadata": {},
   "source": [
    "## 4. Effect of uncorrelated noise on neighbors maps \n",
    "\n",
    "- How is the structure of neighbors maps affected by noise ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9a371-a499-4f0e-a09b-d9a35857d798",
   "metadata": {},
   "source": [
    "**Remark** Adding physical, correlated thermal noise would require a MD engine and an interaction model suited for each crystal structures.\n",
    "\n",
    "Here, for simplicity, we use uncorrelated, Gaussian distributed, noise on the atoms. Note that this is not physical and will eventually lead to atoms overlapping for large displacements (atoms are not repelled by each other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6f713-5829-495e-aaf4-1e2ec3f7dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_structure(atoms, noise):\n",
    "    \"\"\"\n",
    "    Creates a new atomic structure with added noise to the atom positions.\n",
    "\n",
    "    Args:\n",
    "        atoms: The original Atoms object representing the atomic structure.\n",
    "        noise: A float representing the standard deviation (spread) of the \n",
    "               Gaussian noise to be added to each atom's position in each direction (x, y, z).\n",
    "\n",
    "    Returns:\n",
    "        Atoms: A new Atoms object with the perturbed (noisy) atomic positions.\n",
    "    \"\"\"\n",
    "\n",
    "    noisy_atoms = atoms.copy()\n",
    "    noise = np.random.normal(loc=0, scale=noise, size=(atoms.positions.shape[0], 3))\n",
    "    noisy_atoms.positions += noise\n",
    "    return Atoms(noisy_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67a67d-e59f-483d-99a0-1f35912ecbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_neighbors_in_rcut = 64\n",
    "noise_levels = [0, 0.01, 0.05, 0.1, 0.15]\n",
    "\n",
    "rcuts = [get_cutoff(l, number_of_neighbors_in_rcut) for l in lattices]\n",
    "\n",
    "# Create a matplotlib image\n",
    "fig, ax = plt.subplots(len(noise_levels), len(lattices), constrained_layout=True, dpi=200)\n",
    "\n",
    "for i, noise_level in enumerate(noise_levels):\n",
    "    for j, lattice in enumerate(lattices):\n",
    "\n",
    "        # calculate cutoff\n",
    "        rcut = rcuts[j]\n",
    "\n",
    "        # create a noisy structure\n",
    "        noisy_struct = noisy_structure(lattice, noise_level)\n",
    "        \n",
    "        # compute descriptor\n",
    "        image = noisy_struct.get_neighbor_map(0, r_cut=rcut)\n",
    "\n",
    "        # display the image\n",
    "        ax[i, j].imshow(image)\n",
    "        \n",
    "        # deactivate x and y scales as we show images\n",
    "        ax[i, j].axis(\"off\")\n",
    "        ax[i, j].set_title(f\"{bravais_lattices[j][1]}\\n\" + r\"$\\sigma =$\" + f\"{noise_level:.2f}\", fontsize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bd8cc-a48e-46b6-abfc-8b0e1c539ad8",
   "metadata": {},
   "source": [
    "## 5. Getting ready for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fbdb6-eabc-4fbf-b2fa-6b77e88cf087",
   "metadata": {},
   "source": [
    "- Are the images above different enough to be classified ?\n",
    "- To answer, we will try to find a low-dimensional representation of the images that allows to discriminate them.\n",
    "- We will use the PCA and LDA methods.\n",
    "- We will try different cut-off radii, with different levels of noise, on different structures, so this will take approximately a minute (code is not optimized here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ae68b-1f11-4009-bcd8-18aced6f8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_atomic_structures(noise):\n",
    "\n",
    "    # Lists to store data for the analysis\n",
    "    structure_name  = []        # Store the names of the lattice types\n",
    "    structure_label = []        # Store numerical labels for the lattice types (useful for coloring)\n",
    "    all_structures  = []        # Store the flattened neighbor map images\n",
    "\n",
    "    # Loop through each lattice type and its corresponding info (index and name)\n",
    "    for i, (lattice, lat_num, lat_name) in enumerate(zip(lattices, lattice_num, lattice_name)):\n",
    "        # Add noise to the lattice (standard deviation of 0.15 Angstroms)\n",
    "        structure = noisy_structure(lattice, noise) \n",
    "        \n",
    "        all_structures.append(structure)\n",
    "        structure_name.append(lat_name)\n",
    "        structure_label.append(lat_num)\n",
    "    return all_structures, structure_label, structure_name\n",
    "\n",
    "def compute_descriptors(structures, N_neigh = 64, img_size = 32, beta=3, gamma=2, at_per_struct=150, **kwargs):\n",
    "    \n",
    "    # Lists to store data for the analysis\n",
    "    lattice_name_ = []      # Store the names of the lattice types\n",
    "    lattice_num_ = []       # Store numerical labels for the lattice types (useful for coloring)\n",
    "    all_images = []         # Store the flattened neighbor map images\n",
    "    \n",
    "    rng = np.random.default_rng(42) \n",
    "    \n",
    "    # Loop through each lattice type and its corresponding info (index and name)\n",
    "    for i, (lattice, lat_num, lat_name) in enumerate(zip(lattices, lattice_num, lattice_name)):\n",
    "    \n",
    "        # Add noise to the lattice (standard deviation of 0.15 Angstroms)\n",
    "        structure = structures[i]\n",
    "        \n",
    "        cut_off = get_cutoff(lattice, N_neigh) # Calculate cutoff radius to include N_neigh neighbors\n",
    "        \n",
    "        structure.neighbor_map.beta=beta\n",
    "        structure.neighbor_map.gamma=gamma\n",
    "        \n",
    "        # Choose n atoms randomly from the lattice\n",
    "        for at in rng.choice(len(lattice), at_per_struct):  \n",
    "        \n",
    "            # Get the neighbor map for the selected atom and flatten it into a 1D array\n",
    "            image = structure.get_neighbor_map(\n",
    "                at,                                        # Index of the atom to focus on\n",
    "                r_cut = cut_off,     \n",
    "                img_target_size = img_size                 # Image is img_sizeximg_size pixels\n",
    "            ).flatten()  # Convert 2D image to 1D for easier analysis\n",
    "    \n",
    "            # Store the image, lattice number, and lattice name\n",
    "            all_images.append(image) \n",
    "            lattice_num_.append(lat_num)   \n",
    "            lattice_name_.append(lat_name)\n",
    "    \n",
    "    # Convert the list of images to a NumPy array for further analysis (e.g., PCA, LDA)\n",
    "    all_images = np.array(all_images) \n",
    "    return all_images, lattice_name_, lattice_num_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef876f-7cc9-4d41-94cd-93d329c3fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_pca(all_images, lattice_num_, noise_level, axes, column):\n",
    "    \"\"\"\n",
    "    Plots PCA and LDA results for a given set of images and lattice numbers.\n",
    "\n",
    "    Args:\n",
    "        all_images: Array of flattened neighbor map images.\n",
    "        lattice_num_: Array of numerical labels for the lattices.\n",
    "        noise_level: Current noise level.\n",
    "        axes: Axes objects for the subplots.\n",
    "    \"\"\"\n",
    "    model1 = PCA(n_components=2)\n",
    "    model2 = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "    for model_i, m in enumerate([model1, model2]):\n",
    "        if model_i == 0:\n",
    "            # PCA takes only X as input (unsupervised)\n",
    "            model_result = m.fit_transform(all_images)\n",
    "        else:\n",
    "            # LDA takes X and Y as input (supervised)\n",
    "            model_result = m.fit_transform(all_images, lattice_num_)\n",
    "\n",
    "        axes[model_i, column].scatter(\n",
    "            model_result[:, 0],\n",
    "            model_result[:, 1],\n",
    "            color=mpl.cm.tab10(lattice_num_),\n",
    "            s=2,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "        # a trick to add a legend \n",
    "        if (model_i==1) and (column==0):\n",
    "            for i in range(len(lattices)):\n",
    "                axes[1, 0].scatter([], [], s=2, color=mpl.cm.tab10(i), label=lattice_name[i])\n",
    "            axes[model_i, column].legend(fontsize=5, frameon=False)\n",
    "            \n",
    "        axes[model_i, column].set_title(\n",
    "            f\"{['PCA', 'LDA'][model_i]}, \" + r\"$\\sigma=$\" + f\"{noise_level:.2f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def main_plot(noise_levels, number_of_neighbors_in_rcut, beta=3, gamma=2, img_size=32):\n",
    "    fig, axes = plt.subplots(2, len(noise_levels), \n",
    "                            figsize=(10, 4), \n",
    "                            dpi=200, ## To adjust plot size \n",
    "                            constrained_layout=True)\n",
    "\n",
    "    for i_noise, noise_level in enumerate(tqdm(noise_levels)):\n",
    "        all_structures, structure_label, structure_name = create_atomic_structures(noise_level)\n",
    "        all_images, lattice_name_, lattice_num_ = compute_descriptors(all_structures, \n",
    "                                                                    N_neigh=number_of_neighbors_in_rcut, \n",
    "                                                                    img_size=img_size, \n",
    "                                                                    beta=beta, \n",
    "                                                                    gamma=gamma,\n",
    "                                                                    at_per_structure=300,\n",
    "                                                                    )\n",
    "        plot_pca(all_images, lattice_num_, noise_level, axes, i_noise)\n",
    "        \n",
    "    plt.savefig(f\"pca_{number_of_neighbors_in_rcut}_beta{beta}_gamma{gamma}.pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9cc3f-27f7-4979-a1b8-3332f642d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "# Execution for different neighbor counts\n",
    "for n_neigh in [32, 64, 128]:\n",
    "\n",
    "    print(f\"---------- {n_neigh} Neighbors ---------\")\n",
    "    main_plot(noise_levels, n_neigh, img_size=32)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d9767-aba9-488b-83c3-71619ef26e0f",
   "metadata": {},
   "source": [
    "- Which method seems the most efficient for separating clusters ? Does it always work ?\n",
    "- What is the unit or meaning of the plots axis ? \n",
    "- How could we improve the results ?\n",
    "- Can you make the separation better for high noise conditions ?\n",
    "- Is the uncorrelated noise used here representative of thermal noise ?\n",
    "- Do all clusters have approx. the same variance ?\n",
    "- What is the effect of the cut-off radius ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45f8b5-7e21-41fc-9703-6013368dbd7e",
   "metadata": {},
   "source": [
    "## 6. Clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0141d0-be39-4e5b-9c9d-d9416441d389",
   "metadata": {},
   "source": [
    "For the following, let's pick the condition \"64 Neighbors / noise_std = 0.25A\", where it can already be difficult to recognize structures.\n",
    "\n",
    "Now, we will try to cluster the data in an unsupervised or supervised way.\n",
    "\n",
    "To first get a sense of how noisy the structures are, let's visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582546e-05e8-458c-b1c9-89708c56108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "structure = noisy_structure(lattices[2], 0.25)\n",
    "\n",
    "# Let's visualize the atoms coordinates to feel just how displaced atoms are for this level of noise\n",
    "\n",
    "# Next line might work well or freeze the browser for a few seconds (or forever)\n",
    "#view(structure, viewer='ngl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a387d80-8b97-402f-9610-439c8bcda279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A safer alternative visualization method (requires plotly): \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "go.Scatter3d(\n",
    "    x=structure.positions[:, 0],\n",
    "    y=structure.positions[:, 1],\n",
    "    z=structure.positions[:, 2],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        opacity=0.7,\n",
    "    ),\n",
    ")\n",
    ")\n",
    "\n",
    "\n",
    "# Set axis labels and title\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        zaxis_title=\"z\",\n",
    "    ),\n",
    "    title=\"3D positions of the atoms\",\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "fig.layout.scene.camera.projection.type = \"orthographic\"\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c149a-4773-47b3-8a57-14b4ce054f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the associated descriptor\n",
    "# Play with values of gamma and beta to get the most out of the image\n",
    "\n",
    "s = noisy_structure(lattices[2], 0.25)\n",
    "s.neighbor_map.gamma=2/3\n",
    "s.neighbor_map.beta=4\n",
    "plt.imshow(s.get_neighbor_map(24, 8))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a985dda-69cc-4291-8bb7-2b116ef774b9",
   "metadata": {},
   "source": [
    "**Dataset generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48964a2c-9669-4f25-8d59-39106c6fe7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a noise level\n",
    "all_structures, structure_label, structure_name = create_atomic_structures(noise = 0.25)\n",
    "\n",
    "# choose descriptor parameters\n",
    "all_images, _, ground_truth_labels = compute_descriptors(all_structures,\n",
    "                                                    N_neigh = 128,\n",
    "                                                    img_size = 32, \n",
    "                                                    beta=3, \n",
    "                                                    gamma=2, \n",
    "                                                    at_per_struct=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250557c1-8ee1-4b29-9ac4-9ebef3bc88ff",
   "metadata": {},
   "source": [
    "**Unsupervised methods**\n",
    "\n",
    "Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fe83c-a840-49c5-9459-415234875822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "    \n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "def reduce_dimension(data, model=\"pca\", perplexity=20, n_components=2):\n",
    "\n",
    "    if model == \"pca\":\n",
    "        model_lowd = PCA(n_components=n_components)\n",
    "        low_dimension_imgs = model_lowd.fit_transform(all_images)\n",
    "\n",
    "    elif model==\"tsne\":\n",
    "        # Try this ? TSNE is a nonlinear manifold learning method\n",
    "        # See https://distill.pub/2016/misread-tsne/\n",
    "        low_dimension_imgs = TSNE(n_components=n_components, \n",
    "                                   init='random', \n",
    "                                   early_exaggeration=12,\n",
    "                                   n_iter=1000, # called max_iter in recent versions >1.5 \n",
    "                                   perplexity=perplexity # try 1, 20, 50, 100, 500\n",
    "                                 ).fit_transform(all_images)\n",
    "    else: \n",
    "        raise(ValueError(\"Unknown model\"))\n",
    "    return low_dimension_imgs\n",
    "\n",
    "def clusterize_gm(data, ground_truth, ncomponents, n_init=100):\n",
    "\n",
    "    gm = GaussianMixture(n_components=ncomponents, \n",
    "                         n_init=n_init, # Try 1, 10, 100... \n",
    "                         covariance_type=\"full\", \n",
    "                         random_state=0, # for reproducible runs\n",
    "                         #init_params=\"random_from_data\" # \"kmeans\"\n",
    "                        )\n",
    "    \n",
    "    gm.fit(data)\n",
    "\n",
    "    clust = gm.predict(data)\n",
    "    \n",
    "    # A metric of unsupervised clustering methods performance is the Adjusted Rand Index \n",
    "    # (1: perfect agreement with ground truth, 0: equivalent to random assignment)\n",
    "    score = adjusted_rand_score(ground_truth, clust)\n",
    "\n",
    "    return clust, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021a748-185a-4a69-bda7-8085f9b85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try model=\"tsne\" and \"pca\"; perplexity is a parameter for tsne (not used by pca).\n",
    "low_d_images = reduce_dimension(all_images, model=\"tsne\", perplexity=40) \n",
    "\n",
    "# try different values of n_init, the number of attempts of the GM model.\n",
    "clusters, score = clusterize_gm(low_d_images, ground_truth_labels, len(lattices), n_init=100)\n",
    "\n",
    "# For fun, try to fit the images directly, without dimensionality reduction (will take a long time for n_init >> 1). Do you think the result is worth the wait ? \n",
    "# clusters, score = clusterize_gm(all_images, len(lattices))\n",
    "\n",
    "print(\"The obtained score of similarity between the unsupervised clustering and ground truth labels:\")\n",
    "print(\"ARI: \", score)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=144, constrained_layout=True)\n",
    "axes[0].set_title(\"Colored according to our unsupervised clustering\")\n",
    "axes[1].set_title(\"Colored according to ground truth labels\")\n",
    "axes[0].scatter(low_d_images[:, 0], \n",
    "            low_d_images[:, 1], \n",
    "            color=mpl.cm.tab10(clusters), \n",
    "            s=2, alpha=0.8)\n",
    "axes[1].scatter(low_d_images[:, 0], \n",
    "            low_d_images[:, 1], \n",
    "            color=mpl.cm.tab10(ground_truth_labels), \n",
    "            s=2, alpha=0.8)\n",
    "\n",
    "for i in np.unique(ground_truth_labels):\n",
    "    axes[1].scatter([], [], s=2, color=mpl.cm.tab10(i), label=lattice_name[i])\n",
    "axes[1].legend(fontsize=5, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbdf7e-0a13-41a9-9ff7-04d8fbfb7e3c",
   "metadata": {},
   "source": [
    "- How does the method perform when the perplexity parameter varies ?\n",
    "- Can you improve the clustering by tuning beta and gamma ?\n",
    "- Can we do just as good with other unsupervised clustering methods such as KMeans or DBSCAN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a3a76-bf6e-49dc-a2c2-50baa3530bb8",
   "metadata": {},
   "source": [
    "**More unsupervised clustering methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4e0b7-e2e5-4d2c-9e57-64298cb9d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# Dimensionality Reduction (Optional)\n",
    "# you can try without this step\n",
    "low_dimension_imgs = reduce_dimension(all_images, model=\"tsne\") \n",
    "\n",
    "# K-means Clustering\n",
    "kmeans = KMeans(n_clusters=len(lattices), random_state=0, n_init=100)  # Assuming 7 clusters\n",
    "data_classes_kmeans = kmeans.fit_predict(low_dimension_imgs)\n",
    "\n",
    "# DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=10, min_samples=5)  # You'll need to tune eps and min_samples\n",
    "data_classes_dbscan = dbscan.fit_predict(low_dimension_imgs)\n",
    "\n",
    "\n",
    "\n",
    "# Visualization on the two first principal components\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=144, constrained_layout=True)\n",
    "\n",
    "# K-means\n",
    "axes[0].scatter(low_dimension_imgs[:, 0], low_dimension_imgs[:, 1],\n",
    "                c=mpl.cm.tab10(data_classes_kmeans), s=2, alpha=0.8)\n",
    "axes[0].set_title(\"K-means Clustering\")\n",
    "\n",
    "# DBSCAN\n",
    "axes[1].scatter(low_dimension_imgs[:, 0], low_dimension_imgs[:, 1],\n",
    "                c=mpl.cm.tab10(data_classes_dbscan), s=2, alpha=0.8)\n",
    "axes[1].set_title(\"DBSCAN Clustering\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Evaluation (Adjusted Rand Index)\n",
    "ari_kmeans = adjusted_rand_score(ground_truth_labels, data_classes_kmeans)\n",
    "ari_dbscan = adjusted_rand_score(ground_truth_labels, data_classes_dbscan)\n",
    "\n",
    "print(\"ARI (K-means):\", ari_kmeans)\n",
    "print(\"ARI (DBSCAN):\", ari_dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b6c7a-013a-4990-8e4a-fdba835ce83d",
   "metadata": {},
   "source": [
    "- Try different values for `DBSCAN(eps=0.2, min_samples=10)`\n",
    "- Is K-means a deterministic method ? Change the `random_state` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc260fbe-91e9-40f5-a406-69d013915061",
   "metadata": {},
   "source": [
    "## Defect detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1f918-8353-4e7d-99cf-94e0cba7d0d3",
   "metadata": {},
   "source": [
    "Here we try to identify the environment of a vacancy, again in an unsupervised way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4a601-02f2-47d8-a481-5e450b0de74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase.build\n",
    "from neighbors_map import Atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020a48d-da3d-4c12-bd31-bf7e35c003ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can set the element to \"Al\" for fcc, Po for simple cubic, Si for diamond etc\n",
    "bulk_Fe = ase.build.bulk(\"Fe\", cubic=True) * [6, 6, 6]\n",
    "# Level of noise, can be modified \n",
    "bulk_Fe.rattle(0.08)\n",
    "\n",
    "# Create a copy of the system where an atom is missing. The atom is at the center of the cell.\n",
    "vacancy = bulk_Fe.copy()\n",
    "id_to_del = np.argmin(np.linalg.norm(bulk_Fe.positions - bulk_Fe.get_cell()[0, 0]//2, \n",
    "                                    axis=1)\n",
    "                            )\n",
    "\n",
    "del vacancy[id_to_del]\n",
    "\n",
    "bulk_Fe = Atoms(bulk_Fe)\n",
    "vacancy = Atoms(vacancy)\n",
    "\n",
    "# Set the neighbor maps parameters \n",
    "vacancy.neighbor_map.beta=3\n",
    "vacancy.neighbor_map.gamma=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb918f-0316-4ff9-9afe-99868c16cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate the descriptors of the system with vacancy in an array\n",
    "descriptors_bulk = []\n",
    "\n",
    "for i, _ in enumerate(bulk_Fe):\n",
    "    nm = bulk_Fe.get_neighbor_map(i, 8.0)\n",
    "    descriptors_bulk.append(nm.flatten())\n",
    "    \n",
    "descriptors_bulk = np.array(descriptors_bulk)\n",
    "\n",
    "# Accumulate the descriptors of the system with vacancy in an array\n",
    "descriptors_vac = []\n",
    "\n",
    "for i, _ in enumerate(vacancy):\n",
    "    nm = vacancy.get_neighbor_map(i, 8.0)\n",
    "    descriptors_vac.append(nm.flatten())\n",
    "    \n",
    "descriptors_vac = np.array(descriptors_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7977a-d1fd-4a06-b33a-d67548962dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimension with PCA & project descriptors\n",
    "pca = PCA(n_components=2)\n",
    "projected_desc_vac = pca.fit_transform(descriptors_vac)\n",
    "\n",
    "# TSNE performed poorly in my tests, but maybe you can do better ? \n",
    "# projected_desc_vac = TSNE(n_components=2, \n",
    "#                                    init='random', \n",
    "#                                    early_exaggeration=12,\n",
    "#                                    n_iter=1000, # called max_iter in recent versions >1.5 \n",
    "#                                    perplexity=40 # try 1, 20, 50, 100, 500\n",
    "#                                  ).fit_transform(descriptors_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858b157-4fa5-4688-aa31-9f0456a6467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "\n",
    "# Apply 2-class GMM\n",
    "gmm = sklearn.mixture.GaussianMixture(n_components=2, n_init=20, )\n",
    "\n",
    "clusters_vacancy = gmm.fit_predict(projected_desc_vac)\n",
    "\n",
    "# Plot the PCA and the performed clustering \n",
    "plt.scatter(projected_desc_vac[:,0], projected_desc_vac[:,1], color=[mpl.cm.tab10(cv) for cv in clusters_vacancy])\n",
    "\n",
    "# Put the atoms' cartesian positions in a list, grouped per-cluster\n",
    "\n",
    "clusters_cartesian_positions = [vacancy.positions[clusters_vacancy==i] for i in np.unique(clusters_vacancy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f0058-047c-48b7-b7b9-7e22be3d30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "# Plot the defective atoms\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for c_i, c in enumerate(sorted(clusters_cartesian_positions, key=len)):\n",
    "    \n",
    "    level = np.logspace(0, -2, len(clusters_cartesian_positions))[c_i]\n",
    "    fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=c[:, 0],\n",
    "        y=c[:, 1],\n",
    "        z=c[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            opacity=level,\n",
    "            color=level\n",
    "        ),\n",
    "    )\n",
    "    )\n",
    "\n",
    "# Set axis labels and title\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        zaxis_title=\"z\",\n",
    "    ),\n",
    "    title=\"3D positions of the atoms\",\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "fig.layout.scene.camera.projection.type = \"orthographic\"\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331f9a8-7789-402a-b7a9-3c01b7f3b274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
